{"ast":null,"code":"/**\n * Implementation of the data synchronisation protocol that brings a local and a remote document\n * into the same state. This is typically used when two nodes have been disconnected for some time,\n * and need to exchange any changes that happened while they were disconnected. The two nodes that\n * are syncing could be client and server, or server and client, or two peers with symmetric roles.\n *\n * The protocol is based on this paper: Martin Kleppmann and Heidi Howard. Byzantine Eventual\n * Consistency and the Fundamental Limits of Peer-to-Peer Databases. https://arxiv.org/abs/2012.00472\n *\n * The protocol assumes that every time a node successfully syncs with another node, it remembers\n * the current heads (as returned by `Backend.getHeads()`) after the last sync with that node. The\n * next time we try to sync with the same node, we start from the assumption that the other node's\n * document version is no older than the outcome of the last sync, so we only need to exchange any\n * changes that are more recent than the last sync. This assumption may not be true if the other\n * node did not correctly persist its state (perhaps it crashed before writing the result of the\n * last sync to disk), and we fall back to sending the entire document in this case.\n */\nconst Backend = require('./backend');\n\nconst {\n  hexStringToBytes,\n  bytesToHexString,\n  Encoder,\n  Decoder\n} = require('./encoding');\n\nconst {\n  decodeChangeMeta\n} = require('./columnar');\n\nconst {\n  copyObject\n} = require('../src/common');\n\nconst HASH_SIZE = 32; // 256 bits = 32 bytes\n\nconst MESSAGE_TYPE_SYNC = 0x42; // first byte of a sync message, for identification\n\nconst PEER_STATE_TYPE = 0x43; // first byte of an encoded peer state, for identification\n// These constants correspond to a 1% false positive rate. The values can be changed without\n// breaking compatibility of the network protocol, since the parameters used for a particular\n// Bloom filter are encoded in the wire format.\n\nconst BITS_PER_ENTRY = 10,\n      NUM_PROBES = 7;\n/**\n * A Bloom filter implementation that can be serialised to a byte array for transmission\n * over a network. The entries that are added are assumed to already be SHA-256 hashes,\n * so this implementation does not perform its own hashing.\n */\n\nclass BloomFilter {\n  constructor(arg) {\n    if (Array.isArray(arg)) {\n      // arg is an array of SHA256 hashes in hexadecimal encoding\n      this.numEntries = arg.length;\n      this.numBitsPerEntry = BITS_PER_ENTRY;\n      this.numProbes = NUM_PROBES;\n      this.bits = new Uint8Array(Math.ceil(this.numEntries * this.numBitsPerEntry / 8));\n\n      for (let hash of arg) this.addHash(hash);\n    } else if (arg instanceof Uint8Array) {\n      if (arg.byteLength === 0) {\n        this.numEntries = 0;\n        this.numBitsPerEntry = 0;\n        this.numProbes = 0;\n        this.bits = arg;\n      } else {\n        const decoder = new Decoder(arg);\n        this.numEntries = decoder.readUint32();\n        this.numBitsPerEntry = decoder.readUint32();\n        this.numProbes = decoder.readUint32();\n        this.bits = decoder.readRawBytes(Math.ceil(this.numEntries * this.numBitsPerEntry / 8));\n      }\n    } else {\n      throw new TypeError('invalid argument');\n    }\n  }\n  /**\n   * Returns the Bloom filter state, encoded as a byte array.\n   */\n\n\n  get bytes() {\n    if (this.numEntries === 0) return new Uint8Array(0);\n    const encoder = new Encoder();\n    encoder.appendUint32(this.numEntries);\n    encoder.appendUint32(this.numBitsPerEntry);\n    encoder.appendUint32(this.numProbes);\n    encoder.appendRawBytes(this.bits);\n    return encoder.buffer;\n  }\n  /**\n   * Given a SHA-256 hash (as hex string), returns an array of probe indexes indicating which bits\n   * in the Bloom filter need to be tested or set for this particular entry. We do this by\n   * interpreting the first 12 bytes of the hash as three little-endian 32-bit unsigned integers,\n   * and then using triple hashing to compute the probe indexes. The algorithm comes from:\n   *\n   * Peter C. Dillinger and Panagiotis Manolios. Bloom Filters in Probabilistic Verification.\n   * 5th International Conference on Formal Methods in Computer-Aided Design (FMCAD), November 2004.\n   * http://www.ccis.northeastern.edu/home/pete/pub/bloom-filters-verification.pdf\n   */\n\n\n  getProbes(hash) {\n    const hashBytes = hexStringToBytes(hash),\n          modulo = 8 * this.bits.byteLength;\n    if (hashBytes.byteLength !== 32) throw new RangeError(`Not a 256-bit hash: ${hash}`); // on the next three lines, the right shift means interpret value as unsigned\n\n    let x = ((hashBytes[0] | hashBytes[1] << 8 | hashBytes[2] << 16 | hashBytes[3] << 24) >>> 0) % modulo;\n    let y = ((hashBytes[4] | hashBytes[5] << 8 | hashBytes[6] << 16 | hashBytes[7] << 24) >>> 0) % modulo;\n    let z = ((hashBytes[8] | hashBytes[9] << 8 | hashBytes[10] << 16 | hashBytes[11] << 24) >>> 0) % modulo;\n    const probes = [x];\n\n    for (let i = 1; i < this.numProbes; i++) {\n      x = (x + y) % modulo;\n      y = (y + z) % modulo;\n      probes.push(x);\n    }\n\n    return probes;\n  }\n  /**\n   * Sets the Bloom filter bits corresponding to a given SHA-256 hash (given as hex string).\n   */\n\n\n  addHash(hash) {\n    for (let probe of this.getProbes(hash)) {\n      this.bits[probe >>> 3] |= 1 << (probe & 7);\n    }\n  }\n  /**\n   * Tests whether a given SHA-256 hash (given as hex string) is contained in the Bloom filter.\n   */\n\n\n  containsHash(hash) {\n    if (this.numEntries === 0) return false;\n\n    for (let probe of this.getProbes(hash)) {\n      if ((this.bits[probe >>> 3] & 1 << (probe & 7)) === 0) {\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n}\n/**\n * Encodes a sorted array of SHA-256 hashes (as hexadecimal strings) into a byte array.\n */\n\n\nfunction encodeHashes(encoder, hashes) {\n  if (!Array.isArray(hashes)) throw new TypeError('hashes must be an array');\n  encoder.appendUint32(hashes.length);\n\n  for (let i = 0; i < hashes.length; i++) {\n    if (i > 0 && hashes[i - 1] >= hashes[i]) throw new RangeError('hashes must be sorted');\n    const bytes = hexStringToBytes(hashes[i]);\n    if (bytes.byteLength !== HASH_SIZE) throw new TypeError('heads hashes must be 256 bits');\n    encoder.appendRawBytes(bytes);\n  }\n}\n/**\n * Decodes a byte array in the format returned by encodeHashes(), and returns its content as an\n * array of hex strings.\n */\n\n\nfunction decodeHashes(decoder) {\n  let length = decoder.readUint32(),\n      hashes = [];\n\n  for (let i = 0; i < length; i++) {\n    hashes.push(bytesToHexString(decoder.readRawBytes(HASH_SIZE)));\n  }\n\n  return hashes;\n}\n/**\n * Takes a sync message of the form `{heads, need, have, changes}` and encodes it as a byte array for\n * transmission.\n */\n\n\nfunction encodeSyncMessage(message) {\n  const encoder = new Encoder();\n  encoder.appendByte(MESSAGE_TYPE_SYNC);\n  encodeHashes(encoder, message.heads);\n  encodeHashes(encoder, message.need);\n  encoder.appendUint32(message.have.length);\n\n  for (let have of message.have) {\n    encodeHashes(encoder, have.lastSync);\n    encoder.appendPrefixedBytes(have.bloom);\n  }\n\n  encoder.appendUint32(message.changes.length);\n\n  for (let change of message.changes) {\n    encoder.appendPrefixedBytes(change);\n  }\n\n  return encoder.buffer;\n}\n/**\n * Takes a binary-encoded sync message and decodes it into the form `{heads, need, have, changes}`.\n */\n\n\nfunction decodeSyncMessage(bytes) {\n  const decoder = new Decoder(bytes);\n  const messageType = decoder.readByte();\n\n  if (messageType !== MESSAGE_TYPE_SYNC) {\n    throw new RangeError(`Unexpected message type: ${messageType}`);\n  }\n\n  const heads = decodeHashes(decoder);\n  const need = decodeHashes(decoder);\n  const haveCount = decoder.readUint32();\n  let message = {\n    heads,\n    need,\n    have: [],\n    changes: []\n  };\n\n  for (let i = 0; i < haveCount; i++) {\n    const lastSync = decodeHashes(decoder);\n    const bloom = decoder.readPrefixedBytes(decoder);\n    message.have.push({\n      lastSync,\n      bloom\n    });\n  }\n\n  const changeCount = decoder.readUint32();\n\n  for (let i = 0; i < changeCount; i++) {\n    const change = decoder.readPrefixedBytes();\n    message.changes.push(change);\n  } // Ignore any trailing bytes -- they can be used for extensions by future versions of the protocol\n\n\n  return message;\n}\n/**\n * Takes a SyncState and encodes as a byte array those parts of the state that should persist across\n * an application restart or disconnect and reconnect. The ephemeral parts of the state that should\n * be cleared on reconnect are not encoded.\n */\n\n\nfunction encodeSyncState(syncState) {\n  const encoder = new Encoder();\n  encoder.appendByte(PEER_STATE_TYPE);\n  encodeHashes(encoder, syncState.sharedHeads);\n  return encoder.buffer;\n}\n/**\n * Takes a persisted peer state as encoded by `encodeSyncState` and decodes it into a SyncState\n * object. The parts of the peer state that were not encoded are initialised with default values.\n */\n\n\nfunction decodeSyncState(bytes) {\n  const decoder = new Decoder(bytes);\n  const recordType = decoder.readByte();\n\n  if (recordType !== PEER_STATE_TYPE) {\n    throw new RangeError(`Unexpected record type: ${recordType}`);\n  }\n\n  const sharedHeads = decodeHashes(decoder);\n  return Object.assign(initSyncState(), {\n    sharedHeads\n  });\n}\n/**\n * Constructs a Bloom filter containing all changes that are not one of the hashes in\n * `lastSync` or its transitive dependencies. In other words, the filter contains those\n * changes that have been applied since the version identified by `lastSync`. Returns\n * an object of the form `{lastSync, bloom}` as required for the `have` field of a sync\n * message.\n */\n\n\nfunction makeBloomFilter(backend, lastSync) {\n  const newChanges = Backend.getChanges(backend, lastSync);\n  const hashes = newChanges.map(change => decodeChangeMeta(change, true).hash);\n  return {\n    lastSync,\n    bloom: new BloomFilter(hashes).bytes\n  };\n}\n/**\n * Call this function when a sync message is received from another node. The `message` argument\n * needs to already have been decoded using `decodeSyncMessage()`. This function determines the\n * changes that we need to send to the other node in response. Returns an array of changes (as\n * byte arrays).\n */\n\n\nfunction getChangesToSend(backend, have, need) {\n  if (have.length === 0) {\n    return need.map(hash => Backend.getChangeByHash(backend, hash)).filter(change => change !== undefined);\n  }\n\n  let lastSyncHashes = {},\n      bloomFilters = [];\n\n  for (let h of have) {\n    for (let hash of h.lastSync) lastSyncHashes[hash] = true;\n\n    bloomFilters.push(new BloomFilter(h.bloom));\n  } // Get all changes that were added since the last sync\n\n\n  const changes = Backend.getChanges(backend, Object.keys(lastSyncHashes)).map(change => decodeChangeMeta(change, true));\n  let changeHashes = {},\n      dependents = {},\n      hashesToSend = {};\n\n  for (let change of changes) {\n    changeHashes[change.hash] = true; // For each change, make a list of changes that depend on it\n\n    for (let dep of change.deps) {\n      if (!dependents[dep]) dependents[dep] = [];\n      dependents[dep].push(change.hash);\n    } // Exclude any change hashes contained in one or more Bloom filters\n\n\n    if (bloomFilters.every(bloom => !bloom.containsHash(change.hash))) {\n      hashesToSend[change.hash] = true;\n    }\n  } // Include any changes that depend on a Bloom-negative change\n\n\n  let stack = Object.keys(hashesToSend);\n\n  while (stack.length > 0) {\n    const hash = stack.pop();\n\n    if (dependents[hash]) {\n      for (let dep of dependents[hash]) {\n        if (!hashesToSend[dep]) {\n          hashesToSend[dep] = true;\n          stack.push(dep);\n        }\n      }\n    }\n  } // Include any explicitly requested changes\n\n\n  let changesToSend = [];\n\n  for (let hash of need) {\n    hashesToSend[hash] = true;\n\n    if (!changeHashes[hash]) {\n      // Change is not among those returned by getMissingChanges()?\n      const change = Backend.getChangeByHash(backend, hash);\n      if (change) changesToSend.push(change);\n    }\n  } // Return changes in the order they were returned by getMissingChanges()\n\n\n  for (let change of changes) {\n    if (hashesToSend[change.hash]) changesToSend.push(change.change);\n  }\n\n  return changesToSend;\n}\n\nfunction initSyncState() {\n  return {\n    sharedHeads: [],\n    lastSentHeads: [],\n    theirHeads: null,\n    theirNeed: null,\n    theirHave: null,\n    sentHashes: {}\n  };\n}\n\nfunction compareArrays(a, b) {\n  return a.length === b.length && a.every((v, i) => v === b[i]);\n}\n/**\n * Given a backend and what we believe to be the state of our peer, generate a message which tells\n * them about we have and includes any changes we believe they need\n */\n\n\nfunction generateSyncMessage(backend, syncState) {\n  if (!backend) {\n    throw new Error(\"generateSyncMessage called with no Automerge document\");\n  }\n\n  if (!syncState) {\n    throw new Error(\"generateSyncMessage requires a syncState, which can be created with initSyncState()\");\n  }\n\n  let {\n    sharedHeads,\n    lastSentHeads,\n    theirHeads,\n    theirNeed,\n    theirHave,\n    sentHashes\n  } = syncState;\n  const ourHeads = Backend.getHeads(backend); // Hashes to explicitly request from the remote peer: any missing dependencies of unapplied\n  // changes, and any of the remote peer's heads that we don't know about\n\n  const ourNeed = Backend.getMissingDeps(backend, theirHeads || []); // There are two reasons why ourNeed may be nonempty: 1. we might be missing dependencies due to\n  // Bloom filter false positives; 2. we might be missing heads that the other peer mentioned\n  // because they (intentionally) only sent us a subset of changes. In case 1, we leave the `have`\n  // field of the message empty because we just want to fill in the missing dependencies for now.\n  // In case 2, or if ourNeed is empty, we send a Bloom filter to request any unsent changes.\n\n  let ourHave = [];\n\n  if (!theirHeads || ourNeed.every(hash => theirHeads.includes(hash))) {\n    ourHave = [makeBloomFilter(backend, sharedHeads)];\n  } // Fall back to a full re-sync if the sender's last sync state includes hashes\n  // that we don't know. This could happen if we crashed after the last sync and\n  // failed to persist changes that the other node already sent us.\n\n\n  if (theirHave && theirHave.length > 0) {\n    const lastSync = theirHave[0].lastSync;\n\n    if (!lastSync.every(hash => Backend.getChangeByHash(backend, hash))) {\n      // we need to queue them to send us a fresh sync message, the one they sent is uninteligible so we don't know what they need\n      const resetMsg = {\n        heads: ourHeads,\n        need: [],\n        have: [{\n          lastSync: [],\n          bloom: new Uint8Array(0)\n        }],\n        changes: []\n      };\n      return [syncState, encodeSyncMessage(resetMsg)];\n    }\n  } // XXX: we should limit ourselves to only sending a subset of all the messages, probably limited by a total message size\n  //      these changes should ideally be RLE encoded but we haven't implemented that yet.\n\n\n  let changesToSend = Array.isArray(theirHave) && Array.isArray(theirNeed) ? getChangesToSend(backend, theirHave, theirNeed) : []; // If the heads are equal, we're in sync and don't need to do anything further\n\n  const headsUnchanged = Array.isArray(lastSentHeads) && compareArrays(ourHeads, lastSentHeads);\n  const headsEqual = Array.isArray(theirHeads) && compareArrays(ourHeads, theirHeads);\n\n  if (headsUnchanged && headsEqual && changesToSend.length === 0) {\n    // no need to send a sync message if we know we're synced!\n    return [syncState, null];\n  } // TODO: this recomputes the SHA-256 hash of each change; we should restructure this to avoid the\n  // unnecessary recomputation\n\n\n  changesToSend = changesToSend.filter(change => !sentHashes[decodeChangeMeta(change, true).hash]); // Regular response to a sync message: send any changes that the other node\n  // doesn't have. We leave the \"have\" field empty because the previous message\n  // generated by `syncStart` already indicated what changes we have.\n\n  const syncMessage = {\n    heads: ourHeads,\n    have: ourHave,\n    need: ourNeed,\n    changes: changesToSend\n  };\n\n  if (changesToSend.length > 0) {\n    sentHashes = copyObject(sentHashes);\n\n    for (const change of changesToSend) {\n      sentHashes[decodeChangeMeta(change, true).hash] = true;\n    }\n  }\n\n  syncState = Object.assign({}, syncState, {\n    lastSentHeads: ourHeads,\n    sentHashes\n  });\n  return [syncState, encodeSyncMessage(syncMessage)];\n}\n/**\n * Computes the heads that we share with a peer after we have just received some changes from that\n * peer and applied them. This may not be sufficient to bring our heads in sync with the other\n * peer's heads, since they may have only sent us a subset of their outstanding changes.\n *\n * `myOldHeads` are the local heads before the most recent changes were applied, `myNewHeads` are\n * the local heads after those changes were applied, and `ourOldSharedHeads` is the previous set of\n * shared heads. Applying the changes will have replaced some heads with others, but some heads may\n * have remained unchanged (because they are for branches on which no changes have been added). Any\n * such unchanged heads remain in the sharedHeads. Any sharedHeads that were replaced by applying\n * changes are also replaced as sharedHeads. This is safe because if we received some changes from\n * another peer, that means that peer had those changes, and therefore we now both know about them.\n */\n\n\nfunction advanceHeads(myOldHeads, myNewHeads, ourOldSharedHeads) {\n  const newHeads = myNewHeads.filter(head => !myOldHeads.includes(head));\n  const commonHeads = ourOldSharedHeads.filter(head => myNewHeads.includes(head));\n  const advancedHeads = [...new Set([...newHeads, ...commonHeads])].sort();\n  return advancedHeads;\n}\n/**\n * Given a backend, a message message and the state of our peer, apply any changes, update what\n * we believe about the peer, and (if there were applied changes) produce a patch for the frontend\n */\n\n\nfunction receiveSyncMessage(backend, oldSyncState, binaryMessage) {\n  if (!backend) {\n    throw new Error(\"generateSyncMessage called with no Automerge document\");\n  }\n\n  if (!oldSyncState) {\n    throw new Error(\"generateSyncMessage requires a syncState, which can be created with initSyncState()\");\n  }\n\n  let {\n    sharedHeads,\n    lastSentHeads,\n    sentHashes\n  } = oldSyncState,\n      patch = null;\n  const message = decodeSyncMessage(binaryMessage);\n  const beforeHeads = Backend.getHeads(backend); // If we received changes, we try to apply them to the document. There may still be missing\n  // dependencies due to Bloom filter false positives, in which case the backend will enqueue the\n  // changes without applying them. The set of changes may also be incomplete if the sender decided\n  // to break a large set of changes into chunks.\n\n  if (message.changes.length > 0) {\n    [backend, patch] = Backend.applyChanges(backend, message.changes);\n    sharedHeads = advanceHeads(beforeHeads, Backend.getHeads(backend), sharedHeads);\n  } // If heads are equal, indicate we don't need to send a response message\n\n\n  if (message.changes.length === 0 && compareArrays(message.heads, beforeHeads)) {\n    lastSentHeads = message.heads;\n  } // If all of the remote heads are known to us, that means either our heads are equal, or we are\n  // ahead of the remote peer. In this case, take the remote heads to be our shared heads.\n\n\n  const knownHeads = message.heads.filter(head => Backend.getChangeByHash(backend, head));\n\n  if (knownHeads.length === message.heads.length) {\n    sharedHeads = message.heads; // If the remote peer has lost all its data, reset our state to perform a full resync\n\n    if (message.heads.length === 0) {\n      lastSentHeads = [];\n      sentHashes = [];\n    }\n  } else {\n    // If some remote heads are unknown to us, we add all the remote heads we know to\n    // sharedHeads, but don't remove anything from sharedHeads. This might cause sharedHeads to\n    // contain some redundant hashes (where one hash is actually a transitive dependency of\n    // another), but this will be cleared up as soon as we know all the remote heads.\n    sharedHeads = [...new Set(knownHeads.concat(sharedHeads))].sort();\n  }\n\n  const syncState = {\n    sharedHeads,\n    // what we have in common to generate an efficient bloom filter\n    lastSentHeads,\n    theirHave: message.have,\n    // the information we need to calculate the changes they need\n    theirHeads: message.heads,\n    theirNeed: message.need,\n    sentHashes\n  };\n  return [backend, syncState, patch];\n}\n\nmodule.exports = {\n  receiveSyncMessage,\n  generateSyncMessage,\n  encodeSyncMessage,\n  decodeSyncMessage,\n  initSyncState,\n  encodeSyncState,\n  decodeSyncState,\n  BloomFilter // BloomFilter is a private API, exported only for testing purposes\n\n};","map":{"version":3,"sources":["/home/eydwales/Documents/edweis/pepper/node_modules/automerge/backend/sync.js"],"names":["Backend","require","hexStringToBytes","bytesToHexString","Encoder","Decoder","decodeChangeMeta","copyObject","HASH_SIZE","MESSAGE_TYPE_SYNC","PEER_STATE_TYPE","BITS_PER_ENTRY","NUM_PROBES","BloomFilter","constructor","arg","Array","isArray","numEntries","length","numBitsPerEntry","numProbes","bits","Uint8Array","Math","ceil","hash","addHash","byteLength","decoder","readUint32","readRawBytes","TypeError","bytes","encoder","appendUint32","appendRawBytes","buffer","getProbes","hashBytes","modulo","RangeError","x","y","z","probes","i","push","probe","containsHash","encodeHashes","hashes","decodeHashes","encodeSyncMessage","message","appendByte","heads","need","have","lastSync","appendPrefixedBytes","bloom","changes","change","decodeSyncMessage","messageType","readByte","haveCount","readPrefixedBytes","changeCount","encodeSyncState","syncState","sharedHeads","decodeSyncState","recordType","Object","assign","initSyncState","makeBloomFilter","backend","newChanges","getChanges","map","getChangesToSend","getChangeByHash","filter","undefined","lastSyncHashes","bloomFilters","h","keys","changeHashes","dependents","hashesToSend","dep","deps","every","stack","pop","changesToSend","lastSentHeads","theirHeads","theirNeed","theirHave","sentHashes","compareArrays","a","b","v","generateSyncMessage","Error","ourHeads","getHeads","ourNeed","getMissingDeps","ourHave","includes","resetMsg","headsUnchanged","headsEqual","syncMessage","advanceHeads","myOldHeads","myNewHeads","ourOldSharedHeads","newHeads","head","commonHeads","advancedHeads","Set","sort","receiveSyncMessage","oldSyncState","binaryMessage","patch","beforeHeads","applyChanges","knownHeads","concat","module","exports"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA,MAAMA,OAAO,GAAGC,OAAO,CAAC,WAAD,CAAvB;;AACA,MAAM;AAAEC,EAAAA,gBAAF;AAAoBC,EAAAA,gBAApB;AAAsCC,EAAAA,OAAtC;AAA+CC,EAAAA;AAA/C,IAA2DJ,OAAO,CAAC,YAAD,CAAxE;;AACA,MAAM;AAAEK,EAAAA;AAAF,IAAuBL,OAAO,CAAC,YAAD,CAApC;;AACA,MAAM;AAAEM,EAAAA;AAAF,IAAiBN,OAAO,CAAC,eAAD,CAA9B;;AAEA,MAAMO,SAAS,GAAG,EAAlB,C,CAAqB;;AACrB,MAAMC,iBAAiB,GAAG,IAA1B,C,CAA+B;;AAC/B,MAAMC,eAAe,GAAG,IAAxB,C,CAA6B;AAE7B;AACA;AACA;;AACA,MAAMC,cAAc,GAAG,EAAvB;AAAA,MAA2BC,UAAU,GAAG,CAAxC;AAEA;AACA;AACA;AACA;AACA;;AACA,MAAMC,WAAN,CAAkB;AAChBC,EAAAA,WAAW,CAAEC,GAAF,EAAO;AAChB,QAAIC,KAAK,CAACC,OAAN,CAAcF,GAAd,CAAJ,EAAwB;AACtB;AACA,WAAKG,UAAL,GAAkBH,GAAG,CAACI,MAAtB;AACA,WAAKC,eAAL,GAAuBT,cAAvB;AACA,WAAKU,SAAL,GAAiBT,UAAjB;AACA,WAAKU,IAAL,GAAY,IAAIC,UAAJ,CAAeC,IAAI,CAACC,IAAL,CAAU,KAAKP,UAAL,GAAkB,KAAKE,eAAvB,GAAyC,CAAnD,CAAf,CAAZ;;AACA,WAAK,IAAIM,IAAT,IAAiBX,GAAjB,EAAsB,KAAKY,OAAL,CAAaD,IAAb;AACvB,KAPD,MAOO,IAAIX,GAAG,YAAYQ,UAAnB,EAA+B;AACpC,UAAIR,GAAG,CAACa,UAAJ,KAAmB,CAAvB,EAA0B;AACxB,aAAKV,UAAL,GAAkB,CAAlB;AACA,aAAKE,eAAL,GAAuB,CAAvB;AACA,aAAKC,SAAL,GAAiB,CAAjB;AACA,aAAKC,IAAL,GAAYP,GAAZ;AACD,OALD,MAKO;AACL,cAAMc,OAAO,GAAG,IAAIxB,OAAJ,CAAYU,GAAZ,CAAhB;AACA,aAAKG,UAAL,GAAkBW,OAAO,CAACC,UAAR,EAAlB;AACA,aAAKV,eAAL,GAAuBS,OAAO,CAACC,UAAR,EAAvB;AACA,aAAKT,SAAL,GAAiBQ,OAAO,CAACC,UAAR,EAAjB;AACA,aAAKR,IAAL,GAAYO,OAAO,CAACE,YAAR,CAAqBP,IAAI,CAACC,IAAL,CAAU,KAAKP,UAAL,GAAkB,KAAKE,eAAvB,GAAyC,CAAnD,CAArB,CAAZ;AACD;AACF,KAbM,MAaA;AACL,YAAM,IAAIY,SAAJ,CAAc,kBAAd,CAAN;AACD;AACF;AAED;AACF;AACA;;;AACW,MAALC,KAAK,GAAG;AACV,QAAI,KAAKf,UAAL,KAAoB,CAAxB,EAA2B,OAAO,IAAIK,UAAJ,CAAe,CAAf,CAAP;AAC3B,UAAMW,OAAO,GAAG,IAAI9B,OAAJ,EAAhB;AACA8B,IAAAA,OAAO,CAACC,YAAR,CAAqB,KAAKjB,UAA1B;AACAgB,IAAAA,OAAO,CAACC,YAAR,CAAqB,KAAKf,eAA1B;AACAc,IAAAA,OAAO,CAACC,YAAR,CAAqB,KAAKd,SAA1B;AACAa,IAAAA,OAAO,CAACE,cAAR,CAAuB,KAAKd,IAA5B;AACA,WAAOY,OAAO,CAACG,MAAf;AACD;AAED;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACEC,EAAAA,SAAS,CAACZ,IAAD,EAAO;AACd,UAAMa,SAAS,GAAGrC,gBAAgB,CAACwB,IAAD,CAAlC;AAAA,UAA0Cc,MAAM,GAAG,IAAI,KAAKlB,IAAL,CAAUM,UAAjE;AACA,QAAIW,SAAS,CAACX,UAAV,KAAyB,EAA7B,EAAiC,MAAM,IAAIa,UAAJ,CAAgB,uBAAsBf,IAAK,EAA3C,CAAN,CAFnB,CAGd;;AACA,QAAIgB,CAAC,GAAG,CAAC,CAACH,SAAS,CAAC,CAAD,CAAT,GAAeA,SAAS,CAAC,CAAD,CAAT,IAAgB,CAA/B,GAAmCA,SAAS,CAAC,CAAD,CAAT,IAAiB,EAApD,GAAyDA,SAAS,CAAC,CAAD,CAAT,IAAiB,EAA3E,MAAmF,CAApF,IAAyFC,MAAjG;AACA,QAAIG,CAAC,GAAG,CAAC,CAACJ,SAAS,CAAC,CAAD,CAAT,GAAeA,SAAS,CAAC,CAAD,CAAT,IAAgB,CAA/B,GAAmCA,SAAS,CAAC,CAAD,CAAT,IAAiB,EAApD,GAAyDA,SAAS,CAAC,CAAD,CAAT,IAAiB,EAA3E,MAAmF,CAApF,IAAyFC,MAAjG;AACA,QAAII,CAAC,GAAG,CAAC,CAACL,SAAS,CAAC,CAAD,CAAT,GAAeA,SAAS,CAAC,CAAD,CAAT,IAAgB,CAA/B,GAAmCA,SAAS,CAAC,EAAD,CAAT,IAAiB,EAApD,GAAyDA,SAAS,CAAC,EAAD,CAAT,IAAiB,EAA3E,MAAmF,CAApF,IAAyFC,MAAjG;AACA,UAAMK,MAAM,GAAG,CAACH,CAAD,CAAf;;AACA,SAAK,IAAII,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG,KAAKzB,SAAzB,EAAoCyB,CAAC,EAArC,EAAyC;AACvCJ,MAAAA,CAAC,GAAG,CAACA,CAAC,GAAGC,CAAL,IAAUH,MAAd;AACAG,MAAAA,CAAC,GAAG,CAACA,CAAC,GAAGC,CAAL,IAAUJ,MAAd;AACAK,MAAAA,MAAM,CAACE,IAAP,CAAYL,CAAZ;AACD;;AACD,WAAOG,MAAP;AACD;AAED;AACF;AACA;;;AACElB,EAAAA,OAAO,CAACD,IAAD,EAAO;AACZ,SAAK,IAAIsB,KAAT,IAAkB,KAAKV,SAAL,CAAeZ,IAAf,CAAlB,EAAwC;AACtC,WAAKJ,IAAL,CAAU0B,KAAK,KAAK,CAApB,KAA0B,MAAMA,KAAK,GAAG,CAAd,CAA1B;AACD;AACF;AAED;AACF;AACA;;;AACEC,EAAAA,YAAY,CAACvB,IAAD,EAAO;AACjB,QAAI,KAAKR,UAAL,KAAoB,CAAxB,EAA2B,OAAO,KAAP;;AAC3B,SAAK,IAAI8B,KAAT,IAAkB,KAAKV,SAAL,CAAeZ,IAAf,CAAlB,EAAwC;AACtC,UAAI,CAAC,KAAKJ,IAAL,CAAU0B,KAAK,KAAK,CAApB,IAA0B,MAAMA,KAAK,GAAG,CAAd,CAA3B,MAAkD,CAAtD,EAAyD;AACvD,eAAO,KAAP;AACD;AACF;;AACD,WAAO,IAAP;AACD;;AAtFe;AAyFlB;AACA;AACA;;;AACA,SAASE,YAAT,CAAsBhB,OAAtB,EAA+BiB,MAA/B,EAAuC;AACrC,MAAI,CAACnC,KAAK,CAACC,OAAN,CAAckC,MAAd,CAAL,EAA4B,MAAM,IAAInB,SAAJ,CAAc,yBAAd,CAAN;AAC5BE,EAAAA,OAAO,CAACC,YAAR,CAAqBgB,MAAM,CAAChC,MAA5B;;AACA,OAAK,IAAI2B,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGK,MAAM,CAAChC,MAA3B,EAAmC2B,CAAC,EAApC,EAAwC;AACtC,QAAIA,CAAC,GAAG,CAAJ,IAASK,MAAM,CAACL,CAAC,GAAG,CAAL,CAAN,IAAiBK,MAAM,CAACL,CAAD,CAApC,EAAyC,MAAM,IAAIL,UAAJ,CAAe,uBAAf,CAAN;AACzC,UAAMR,KAAK,GAAG/B,gBAAgB,CAACiD,MAAM,CAACL,CAAD,CAAP,CAA9B;AACA,QAAIb,KAAK,CAACL,UAAN,KAAqBpB,SAAzB,EAAoC,MAAM,IAAIwB,SAAJ,CAAc,+BAAd,CAAN;AACpCE,IAAAA,OAAO,CAACE,cAAR,CAAuBH,KAAvB;AACD;AACF;AAED;AACA;AACA;AACA;;;AACA,SAASmB,YAAT,CAAsBvB,OAAtB,EAA+B;AAC7B,MAAIV,MAAM,GAAGU,OAAO,CAACC,UAAR,EAAb;AAAA,MAAmCqB,MAAM,GAAG,EAA5C;;AACA,OAAK,IAAIL,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG3B,MAApB,EAA4B2B,CAAC,EAA7B,EAAiC;AAC/BK,IAAAA,MAAM,CAACJ,IAAP,CAAY5C,gBAAgB,CAAC0B,OAAO,CAACE,YAAR,CAAqBvB,SAArB,CAAD,CAA5B;AACD;;AACD,SAAO2C,MAAP;AACD;AAED;AACA;AACA;AACA;;;AACA,SAASE,iBAAT,CAA2BC,OAA3B,EAAoC;AAClC,QAAMpB,OAAO,GAAG,IAAI9B,OAAJ,EAAhB;AACA8B,EAAAA,OAAO,CAACqB,UAAR,CAAmB9C,iBAAnB;AACAyC,EAAAA,YAAY,CAAChB,OAAD,EAAUoB,OAAO,CAACE,KAAlB,CAAZ;AACAN,EAAAA,YAAY,CAAChB,OAAD,EAAUoB,OAAO,CAACG,IAAlB,CAAZ;AACAvB,EAAAA,OAAO,CAACC,YAAR,CAAqBmB,OAAO,CAACI,IAAR,CAAavC,MAAlC;;AACA,OAAK,IAAIuC,IAAT,IAAiBJ,OAAO,CAACI,IAAzB,EAA+B;AAC7BR,IAAAA,YAAY,CAAChB,OAAD,EAAUwB,IAAI,CAACC,QAAf,CAAZ;AACAzB,IAAAA,OAAO,CAAC0B,mBAAR,CAA4BF,IAAI,CAACG,KAAjC;AACD;;AACD3B,EAAAA,OAAO,CAACC,YAAR,CAAqBmB,OAAO,CAACQ,OAAR,CAAgB3C,MAArC;;AACA,OAAK,IAAI4C,MAAT,IAAmBT,OAAO,CAACQ,OAA3B,EAAoC;AAClC5B,IAAAA,OAAO,CAAC0B,mBAAR,CAA4BG,MAA5B;AACD;;AACD,SAAO7B,OAAO,CAACG,MAAf;AACD;AAED;AACA;AACA;;;AACA,SAAS2B,iBAAT,CAA2B/B,KAA3B,EAAkC;AAChC,QAAMJ,OAAO,GAAG,IAAIxB,OAAJ,CAAY4B,KAAZ,CAAhB;AACA,QAAMgC,WAAW,GAAGpC,OAAO,CAACqC,QAAR,EAApB;;AACA,MAAID,WAAW,KAAKxD,iBAApB,EAAuC;AACrC,UAAM,IAAIgC,UAAJ,CAAgB,4BAA2BwB,WAAY,EAAvD,CAAN;AACD;;AACD,QAAMT,KAAK,GAAGJ,YAAY,CAACvB,OAAD,CAA1B;AACA,QAAM4B,IAAI,GAAGL,YAAY,CAACvB,OAAD,CAAzB;AACA,QAAMsC,SAAS,GAAGtC,OAAO,CAACC,UAAR,EAAlB;AACA,MAAIwB,OAAO,GAAG;AAACE,IAAAA,KAAD;AAAQC,IAAAA,IAAR;AAAcC,IAAAA,IAAI,EAAE,EAApB;AAAwBI,IAAAA,OAAO,EAAE;AAAjC,GAAd;;AACA,OAAK,IAAIhB,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGqB,SAApB,EAA+BrB,CAAC,EAAhC,EAAoC;AAClC,UAAMa,QAAQ,GAAGP,YAAY,CAACvB,OAAD,CAA7B;AACA,UAAMgC,KAAK,GAAGhC,OAAO,CAACuC,iBAAR,CAA0BvC,OAA1B,CAAd;AACAyB,IAAAA,OAAO,CAACI,IAAR,CAAaX,IAAb,CAAkB;AAACY,MAAAA,QAAD;AAAWE,MAAAA;AAAX,KAAlB;AACD;;AACD,QAAMQ,WAAW,GAAGxC,OAAO,CAACC,UAAR,EAApB;;AACA,OAAK,IAAIgB,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGuB,WAApB,EAAiCvB,CAAC,EAAlC,EAAsC;AACpC,UAAMiB,MAAM,GAAGlC,OAAO,CAACuC,iBAAR,EAAf;AACAd,IAAAA,OAAO,CAACQ,OAAR,CAAgBf,IAAhB,CAAqBgB,MAArB;AACD,GAnB+B,CAoBhC;;;AACA,SAAOT,OAAP;AACD;AAED;AACA;AACA;AACA;AACA;;;AACA,SAASgB,eAAT,CAAyBC,SAAzB,EAAoC;AAClC,QAAMrC,OAAO,GAAG,IAAI9B,OAAJ,EAAhB;AACA8B,EAAAA,OAAO,CAACqB,UAAR,CAAmB7C,eAAnB;AACAwC,EAAAA,YAAY,CAAChB,OAAD,EAAUqC,SAAS,CAACC,WAApB,CAAZ;AACA,SAAOtC,OAAO,CAACG,MAAf;AACD;AAED;AACA;AACA;AACA;;;AACA,SAASoC,eAAT,CAAyBxC,KAAzB,EAAgC;AAC9B,QAAMJ,OAAO,GAAG,IAAIxB,OAAJ,CAAY4B,KAAZ,CAAhB;AACA,QAAMyC,UAAU,GAAG7C,OAAO,CAACqC,QAAR,EAAnB;;AACA,MAAIQ,UAAU,KAAKhE,eAAnB,EAAoC;AAClC,UAAM,IAAI+B,UAAJ,CAAgB,2BAA0BiC,UAAW,EAArD,CAAN;AACD;;AACD,QAAMF,WAAW,GAAGpB,YAAY,CAACvB,OAAD,CAAhC;AACA,SAAO8C,MAAM,CAACC,MAAP,CAAcC,aAAa,EAA3B,EAA+B;AAAEL,IAAAA;AAAF,GAA/B,CAAP;AACD;AAED;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,SAASM,eAAT,CAAyBC,OAAzB,EAAkCpB,QAAlC,EAA4C;AAC1C,QAAMqB,UAAU,GAAGhF,OAAO,CAACiF,UAAR,CAAmBF,OAAnB,EAA4BpB,QAA5B,CAAnB;AACA,QAAMR,MAAM,GAAG6B,UAAU,CAACE,GAAX,CAAenB,MAAM,IAAIzD,gBAAgB,CAACyD,MAAD,EAAS,IAAT,CAAhB,CAA+BrC,IAAxD,CAAf;AACA,SAAO;AAACiC,IAAAA,QAAD;AAAWE,IAAAA,KAAK,EAAE,IAAIhD,WAAJ,CAAgBsC,MAAhB,EAAwBlB;AAA1C,GAAP;AACD;AAED;AACA;AACA;AACA;AACA;AACA;;;AACA,SAASkD,gBAAT,CAA0BJ,OAA1B,EAAmCrB,IAAnC,EAAyCD,IAAzC,EAA+C;AAC7C,MAAIC,IAAI,CAACvC,MAAL,KAAgB,CAApB,EAAuB;AACrB,WAAOsC,IAAI,CAACyB,GAAL,CAASxD,IAAI,IAAI1B,OAAO,CAACoF,eAAR,CAAwBL,OAAxB,EAAiCrD,IAAjC,CAAjB,EAAyD2D,MAAzD,CAAgEtB,MAAM,IAAIA,MAAM,KAAKuB,SAArF,CAAP;AACD;;AAED,MAAIC,cAAc,GAAG,EAArB;AAAA,MAAyBC,YAAY,GAAG,EAAxC;;AACA,OAAK,IAAIC,CAAT,IAAc/B,IAAd,EAAoB;AAClB,SAAK,IAAIhC,IAAT,IAAiB+D,CAAC,CAAC9B,QAAnB,EAA6B4B,cAAc,CAAC7D,IAAD,CAAd,GAAuB,IAAvB;;AAC7B8D,IAAAA,YAAY,CAACzC,IAAb,CAAkB,IAAIlC,WAAJ,CAAgB4E,CAAC,CAAC5B,KAAlB,CAAlB;AACD,GAT4C,CAW7C;;;AACA,QAAMC,OAAO,GAAG9D,OAAO,CAACiF,UAAR,CAAmBF,OAAnB,EAA4BJ,MAAM,CAACe,IAAP,CAAYH,cAAZ,CAA5B,EACbL,GADa,CACTnB,MAAM,IAAIzD,gBAAgB,CAACyD,MAAD,EAAS,IAAT,CADjB,CAAhB;AAGA,MAAI4B,YAAY,GAAG,EAAnB;AAAA,MAAuBC,UAAU,GAAG,EAApC;AAAA,MAAwCC,YAAY,GAAG,EAAvD;;AACA,OAAK,IAAI9B,MAAT,IAAmBD,OAAnB,EAA4B;AAC1B6B,IAAAA,YAAY,CAAC5B,MAAM,CAACrC,IAAR,CAAZ,GAA4B,IAA5B,CAD0B,CAG1B;;AACA,SAAK,IAAIoE,GAAT,IAAgB/B,MAAM,CAACgC,IAAvB,EAA6B;AAC3B,UAAI,CAACH,UAAU,CAACE,GAAD,CAAf,EAAsBF,UAAU,CAACE,GAAD,CAAV,GAAkB,EAAlB;AACtBF,MAAAA,UAAU,CAACE,GAAD,CAAV,CAAgB/C,IAAhB,CAAqBgB,MAAM,CAACrC,IAA5B;AACD,KAPyB,CAS1B;;;AACA,QAAI8D,YAAY,CAACQ,KAAb,CAAmBnC,KAAK,IAAI,CAACA,KAAK,CAACZ,YAAN,CAAmBc,MAAM,CAACrC,IAA1B,CAA7B,CAAJ,EAAmE;AACjEmE,MAAAA,YAAY,CAAC9B,MAAM,CAACrC,IAAR,CAAZ,GAA4B,IAA5B;AACD;AACF,GA7B4C,CA+B7C;;;AACA,MAAIuE,KAAK,GAAGtB,MAAM,CAACe,IAAP,CAAYG,YAAZ,CAAZ;;AACA,SAAOI,KAAK,CAAC9E,MAAN,GAAe,CAAtB,EAAyB;AACvB,UAAMO,IAAI,GAAGuE,KAAK,CAACC,GAAN,EAAb;;AACA,QAAIN,UAAU,CAAClE,IAAD,CAAd,EAAsB;AACpB,WAAK,IAAIoE,GAAT,IAAgBF,UAAU,CAAClE,IAAD,CAA1B,EAAkC;AAChC,YAAI,CAACmE,YAAY,CAACC,GAAD,CAAjB,EAAwB;AACtBD,UAAAA,YAAY,CAACC,GAAD,CAAZ,GAAoB,IAApB;AACAG,UAAAA,KAAK,CAAClD,IAAN,CAAW+C,GAAX;AACD;AACF;AACF;AACF,GA3C4C,CA6C7C;;;AACA,MAAIK,aAAa,GAAG,EAApB;;AACA,OAAK,IAAIzE,IAAT,IAAiB+B,IAAjB,EAAuB;AACrBoC,IAAAA,YAAY,CAACnE,IAAD,CAAZ,GAAqB,IAArB;;AACA,QAAI,CAACiE,YAAY,CAACjE,IAAD,CAAjB,EAAyB;AAAE;AACzB,YAAMqC,MAAM,GAAG/D,OAAO,CAACoF,eAAR,CAAwBL,OAAxB,EAAiCrD,IAAjC,CAAf;AACA,UAAIqC,MAAJ,EAAYoC,aAAa,CAACpD,IAAd,CAAmBgB,MAAnB;AACb;AACF,GArD4C,CAuD7C;;;AACA,OAAK,IAAIA,MAAT,IAAmBD,OAAnB,EAA4B;AAC1B,QAAI+B,YAAY,CAAC9B,MAAM,CAACrC,IAAR,CAAhB,EAA+ByE,aAAa,CAACpD,IAAd,CAAmBgB,MAAM,CAACA,MAA1B;AAChC;;AACD,SAAOoC,aAAP;AACD;;AAED,SAAStB,aAAT,GAAyB;AACvB,SAAO;AACLL,IAAAA,WAAW,EAAE,EADR;AAEL4B,IAAAA,aAAa,EAAE,EAFV;AAGLC,IAAAA,UAAU,EAAE,IAHP;AAILC,IAAAA,SAAS,EAAE,IAJN;AAKLC,IAAAA,SAAS,EAAE,IALN;AAMLC,IAAAA,UAAU,EAAE;AANP,GAAP;AAQD;;AAED,SAASC,aAAT,CAAuBC,CAAvB,EAA0BC,CAA1B,EAA6B;AACzB,SAAQD,CAAC,CAACvF,MAAF,KAAawF,CAAC,CAACxF,MAAhB,IAA2BuF,CAAC,CAACV,KAAF,CAAQ,CAACY,CAAD,EAAI9D,CAAJ,KAAU8D,CAAC,KAAKD,CAAC,CAAC7D,CAAD,CAAzB,CAAlC;AACH;AAED;AACA;AACA;AACA;;;AACA,SAAS+D,mBAAT,CAA6B9B,OAA7B,EAAsCR,SAAtC,EAAiD;AAC/C,MAAI,CAACQ,OAAL,EAAc;AACZ,UAAM,IAAI+B,KAAJ,CAAU,uDAAV,CAAN;AACD;;AACD,MAAI,CAACvC,SAAL,EAAgB;AACd,UAAM,IAAIuC,KAAJ,CAAU,qFAAV,CAAN;AACD;;AAED,MAAI;AAAEtC,IAAAA,WAAF;AAAe4B,IAAAA,aAAf;AAA8BC,IAAAA,UAA9B;AAA0CC,IAAAA,SAA1C;AAAqDC,IAAAA,SAArD;AAAgEC,IAAAA;AAAhE,MAA+EjC,SAAnF;AACA,QAAMwC,QAAQ,GAAG/G,OAAO,CAACgH,QAAR,CAAiBjC,OAAjB,CAAjB,CAT+C,CAW/C;AACA;;AACA,QAAMkC,OAAO,GAAGjH,OAAO,CAACkH,cAAR,CAAuBnC,OAAvB,EAAgCsB,UAAU,IAAI,EAA9C,CAAhB,CAb+C,CAe/C;AACA;AACA;AACA;AACA;;AACA,MAAIc,OAAO,GAAG,EAAd;;AACA,MAAI,CAACd,UAAD,IAAeY,OAAO,CAACjB,KAAR,CAActE,IAAI,IAAI2E,UAAU,CAACe,QAAX,CAAoB1F,IAApB,CAAtB,CAAnB,EAAqE;AACnEyF,IAAAA,OAAO,GAAG,CAACrC,eAAe,CAACC,OAAD,EAAUP,WAAV,CAAhB,CAAV;AACD,GAvB8C,CAyB/C;AACA;AACA;;;AACA,MAAI+B,SAAS,IAAIA,SAAS,CAACpF,MAAV,GAAmB,CAApC,EAAuC;AACrC,UAAMwC,QAAQ,GAAG4C,SAAS,CAAC,CAAD,CAAT,CAAa5C,QAA9B;;AACA,QAAI,CAACA,QAAQ,CAACqC,KAAT,CAAetE,IAAI,IAAI1B,OAAO,CAACoF,eAAR,CAAwBL,OAAxB,EAAiCrD,IAAjC,CAAvB,CAAL,EAAqE;AACnE;AACA,YAAM2F,QAAQ,GAAG;AAAC7D,QAAAA,KAAK,EAAEuD,QAAR;AAAkBtD,QAAAA,IAAI,EAAE,EAAxB;AAA4BC,QAAAA,IAAI,EAAE,CAAC;AAAEC,UAAAA,QAAQ,EAAE,EAAZ;AAAgBE,UAAAA,KAAK,EAAE,IAAItC,UAAJ,CAAe,CAAf;AAAvB,SAAD,CAAlC;AAAgFuC,QAAAA,OAAO,EAAE;AAAzF,OAAjB;AACA,aAAO,CAACS,SAAD,EAAYlB,iBAAiB,CAACgE,QAAD,CAA7B,CAAP;AACD;AACF,GAnC8C,CAqC/C;AACA;;;AACA,MAAIlB,aAAa,GAAGnF,KAAK,CAACC,OAAN,CAAcsF,SAAd,KAA4BvF,KAAK,CAACC,OAAN,CAAcqF,SAAd,CAA5B,GAAuDnB,gBAAgB,CAACJ,OAAD,EAAUwB,SAAV,EAAqBD,SAArB,CAAvE,GAAyG,EAA7H,CAvC+C,CAyC/C;;AACA,QAAMgB,cAAc,GAAGtG,KAAK,CAACC,OAAN,CAAcmF,aAAd,KAAgCK,aAAa,CAACM,QAAD,EAAWX,aAAX,CAApE;AACA,QAAMmB,UAAU,GAAGvG,KAAK,CAACC,OAAN,CAAcoF,UAAd,KAA6BI,aAAa,CAACM,QAAD,EAAWV,UAAX,CAA7D;;AACA,MAAIiB,cAAc,IAAIC,UAAlB,IAAgCpB,aAAa,CAAChF,MAAd,KAAyB,CAA7D,EAAgE;AAC9D;AACA,WAAO,CAACoD,SAAD,EAAY,IAAZ,CAAP;AACD,GA/C8C,CAiD/C;AACA;;;AACA4B,EAAAA,aAAa,GAAGA,aAAa,CAACd,MAAd,CAAqBtB,MAAM,IAAI,CAACyC,UAAU,CAAClG,gBAAgB,CAACyD,MAAD,EAAS,IAAT,CAAhB,CAA+BrC,IAAhC,CAA1C,CAAhB,CAnD+C,CAqD/C;AACA;AACA;;AACA,QAAM8F,WAAW,GAAG;AAAChE,IAAAA,KAAK,EAAEuD,QAAR;AAAkBrD,IAAAA,IAAI,EAAEyD,OAAxB;AAAiC1D,IAAAA,IAAI,EAAEwD,OAAvC;AAAgDnD,IAAAA,OAAO,EAAEqC;AAAzD,GAApB;;AACA,MAAIA,aAAa,CAAChF,MAAd,GAAuB,CAA3B,EAA8B;AAC5BqF,IAAAA,UAAU,GAAGjG,UAAU,CAACiG,UAAD,CAAvB;;AACA,SAAK,MAAMzC,MAAX,IAAqBoC,aAArB,EAAoC;AAClCK,MAAAA,UAAU,CAAClG,gBAAgB,CAACyD,MAAD,EAAS,IAAT,CAAhB,CAA+BrC,IAAhC,CAAV,GAAkD,IAAlD;AACD;AACF;;AAED6C,EAAAA,SAAS,GAAGI,MAAM,CAACC,MAAP,CAAc,EAAd,EAAkBL,SAAlB,EAA6B;AAAC6B,IAAAA,aAAa,EAAEW,QAAhB;AAA0BP,IAAAA;AAA1B,GAA7B,CAAZ;AACA,SAAO,CAACjC,SAAD,EAAYlB,iBAAiB,CAACmE,WAAD,CAA7B,CAAP;AACD;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,SAASC,YAAT,CAAsBC,UAAtB,EAAkCC,UAAlC,EAA8CC,iBAA9C,EAAiE;AAC/D,QAAMC,QAAQ,GAAGF,UAAU,CAACtC,MAAX,CAAmByC,IAAD,IAAU,CAACJ,UAAU,CAACN,QAAX,CAAoBU,IAApB,CAA7B,CAAjB;AACA,QAAMC,WAAW,GAAGH,iBAAiB,CAACvC,MAAlB,CAA0ByC,IAAD,IAAUH,UAAU,CAACP,QAAX,CAAoBU,IAApB,CAAnC,CAApB;AACA,QAAME,aAAa,GAAG,CAAC,GAAG,IAAIC,GAAJ,CAAQ,CAAC,GAAGJ,QAAJ,EAAc,GAAGE,WAAjB,CAAR,CAAJ,EAA4CG,IAA5C,EAAtB;AACA,SAAOF,aAAP;AACD;AAGD;AACA;AACA;AACA;;;AACA,SAASG,kBAAT,CAA4BpD,OAA5B,EAAqCqD,YAArC,EAAmDC,aAAnD,EAAkE;AAChE,MAAI,CAACtD,OAAL,EAAc;AACZ,UAAM,IAAI+B,KAAJ,CAAU,uDAAV,CAAN;AACD;;AACD,MAAI,CAACsB,YAAL,EAAmB;AACjB,UAAM,IAAItB,KAAJ,CAAU,qFAAV,CAAN;AACD;;AAED,MAAI;AAAEtC,IAAAA,WAAF;AAAe4B,IAAAA,aAAf;AAA8BI,IAAAA;AAA9B,MAA6C4B,YAAjD;AAAA,MAA+DE,KAAK,GAAG,IAAvE;AACA,QAAMhF,OAAO,GAAGU,iBAAiB,CAACqE,aAAD,CAAjC;AACA,QAAME,WAAW,GAAGvI,OAAO,CAACgH,QAAR,CAAiBjC,OAAjB,CAApB,CAVgE,CAYhE;AACA;AACA;AACA;;AACA,MAAIzB,OAAO,CAACQ,OAAR,CAAgB3C,MAAhB,GAAyB,CAA7B,EAAgC;AAC9B,KAAC4D,OAAD,EAAUuD,KAAV,IAAmBtI,OAAO,CAACwI,YAAR,CAAqBzD,OAArB,EAA8BzB,OAAO,CAACQ,OAAtC,CAAnB;AACAU,IAAAA,WAAW,GAAGiD,YAAY,CAACc,WAAD,EAAcvI,OAAO,CAACgH,QAAR,CAAiBjC,OAAjB,CAAd,EAAyCP,WAAzC,CAA1B;AACD,GAnB+D,CAqBhE;;;AACA,MAAIlB,OAAO,CAACQ,OAAR,CAAgB3C,MAAhB,KAA2B,CAA3B,IAAgCsF,aAAa,CAACnD,OAAO,CAACE,KAAT,EAAgB+E,WAAhB,CAAjD,EAA+E;AAC7EnC,IAAAA,aAAa,GAAG9C,OAAO,CAACE,KAAxB;AACD,GAxB+D,CA0BhE;AACA;;;AACA,QAAMiF,UAAU,GAAGnF,OAAO,CAACE,KAAR,CAAc6B,MAAd,CAAqByC,IAAI,IAAI9H,OAAO,CAACoF,eAAR,CAAwBL,OAAxB,EAAiC+C,IAAjC,CAA7B,CAAnB;;AACA,MAAIW,UAAU,CAACtH,MAAX,KAAsBmC,OAAO,CAACE,KAAR,CAAcrC,MAAxC,EAAgD;AAC9CqD,IAAAA,WAAW,GAAGlB,OAAO,CAACE,KAAtB,CAD8C,CAE9C;;AACA,QAAIF,OAAO,CAACE,KAAR,CAAcrC,MAAd,KAAyB,CAA7B,EAAgC;AAC9BiF,MAAAA,aAAa,GAAG,EAAhB;AACAI,MAAAA,UAAU,GAAG,EAAb;AACD;AACF,GAPD,MAOO;AACL;AACA;AACA;AACA;AACAhC,IAAAA,WAAW,GAAG,CAAC,GAAG,IAAIyD,GAAJ,CAAQQ,UAAU,CAACC,MAAX,CAAkBlE,WAAlB,CAAR,CAAJ,EAA6C0D,IAA7C,EAAd;AACD;;AAED,QAAM3D,SAAS,GAAG;AAChBC,IAAAA,WADgB;AACH;AACb4B,IAAAA,aAFgB;AAGhBG,IAAAA,SAAS,EAAEjD,OAAO,CAACI,IAHH;AAGS;AACzB2C,IAAAA,UAAU,EAAE/C,OAAO,CAACE,KAJJ;AAKhB8C,IAAAA,SAAS,EAAEhD,OAAO,CAACG,IALH;AAMhB+C,IAAAA;AANgB,GAAlB;AAQA,SAAO,CAACzB,OAAD,EAAUR,SAAV,EAAqB+D,KAArB,CAAP;AACD;;AAEDK,MAAM,CAACC,OAAP,GAAiB;AACfT,EAAAA,kBADe;AACKtB,EAAAA,mBADL;AAEfxD,EAAAA,iBAFe;AAEIW,EAAAA,iBAFJ;AAGfa,EAAAA,aAHe;AAGAP,EAAAA,eAHA;AAGiBG,EAAAA,eAHjB;AAIf5D,EAAAA,WAJe,CAIH;;AAJG,CAAjB","sourcesContent":["/**\n * Implementation of the data synchronisation protocol that brings a local and a remote document\n * into the same state. This is typically used when two nodes have been disconnected for some time,\n * and need to exchange any changes that happened while they were disconnected. The two nodes that\n * are syncing could be client and server, or server and client, or two peers with symmetric roles.\n *\n * The protocol is based on this paper: Martin Kleppmann and Heidi Howard. Byzantine Eventual\n * Consistency and the Fundamental Limits of Peer-to-Peer Databases. https://arxiv.org/abs/2012.00472\n *\n * The protocol assumes that every time a node successfully syncs with another node, it remembers\n * the current heads (as returned by `Backend.getHeads()`) after the last sync with that node. The\n * next time we try to sync with the same node, we start from the assumption that the other node's\n * document version is no older than the outcome of the last sync, so we only need to exchange any\n * changes that are more recent than the last sync. This assumption may not be true if the other\n * node did not correctly persist its state (perhaps it crashed before writing the result of the\n * last sync to disk), and we fall back to sending the entire document in this case.\n */\n\nconst Backend = require('./backend')\nconst { hexStringToBytes, bytesToHexString, Encoder, Decoder } = require('./encoding')\nconst { decodeChangeMeta } = require('./columnar')\nconst { copyObject } = require('../src/common')\n\nconst HASH_SIZE = 32 // 256 bits = 32 bytes\nconst MESSAGE_TYPE_SYNC = 0x42 // first byte of a sync message, for identification\nconst PEER_STATE_TYPE = 0x43 // first byte of an encoded peer state, for identification\n\n// These constants correspond to a 1% false positive rate. The values can be changed without\n// breaking compatibility of the network protocol, since the parameters used for a particular\n// Bloom filter are encoded in the wire format.\nconst BITS_PER_ENTRY = 10, NUM_PROBES = 7\n\n/**\n * A Bloom filter implementation that can be serialised to a byte array for transmission\n * over a network. The entries that are added are assumed to already be SHA-256 hashes,\n * so this implementation does not perform its own hashing.\n */\nclass BloomFilter {\n  constructor (arg) {\n    if (Array.isArray(arg)) {\n      // arg is an array of SHA256 hashes in hexadecimal encoding\n      this.numEntries = arg.length\n      this.numBitsPerEntry = BITS_PER_ENTRY\n      this.numProbes = NUM_PROBES\n      this.bits = new Uint8Array(Math.ceil(this.numEntries * this.numBitsPerEntry / 8))\n      for (let hash of arg) this.addHash(hash)\n    } else if (arg instanceof Uint8Array) {\n      if (arg.byteLength === 0) {\n        this.numEntries = 0\n        this.numBitsPerEntry = 0\n        this.numProbes = 0\n        this.bits = arg\n      } else {\n        const decoder = new Decoder(arg)\n        this.numEntries = decoder.readUint32()\n        this.numBitsPerEntry = decoder.readUint32()\n        this.numProbes = decoder.readUint32()\n        this.bits = decoder.readRawBytes(Math.ceil(this.numEntries * this.numBitsPerEntry / 8))\n      }\n    } else {\n      throw new TypeError('invalid argument')\n    }\n  }\n\n  /**\n   * Returns the Bloom filter state, encoded as a byte array.\n   */\n  get bytes() {\n    if (this.numEntries === 0) return new Uint8Array(0)\n    const encoder = new Encoder()\n    encoder.appendUint32(this.numEntries)\n    encoder.appendUint32(this.numBitsPerEntry)\n    encoder.appendUint32(this.numProbes)\n    encoder.appendRawBytes(this.bits)\n    return encoder.buffer\n  }\n\n  /**\n   * Given a SHA-256 hash (as hex string), returns an array of probe indexes indicating which bits\n   * in the Bloom filter need to be tested or set for this particular entry. We do this by\n   * interpreting the first 12 bytes of the hash as three little-endian 32-bit unsigned integers,\n   * and then using triple hashing to compute the probe indexes. The algorithm comes from:\n   *\n   * Peter C. Dillinger and Panagiotis Manolios. Bloom Filters in Probabilistic Verification.\n   * 5th International Conference on Formal Methods in Computer-Aided Design (FMCAD), November 2004.\n   * http://www.ccis.northeastern.edu/home/pete/pub/bloom-filters-verification.pdf\n   */\n  getProbes(hash) {\n    const hashBytes = hexStringToBytes(hash), modulo = 8 * this.bits.byteLength\n    if (hashBytes.byteLength !== 32) throw new RangeError(`Not a 256-bit hash: ${hash}`)\n    // on the next three lines, the right shift means interpret value as unsigned\n    let x = ((hashBytes[0] | hashBytes[1] << 8 | hashBytes[2]  << 16 | hashBytes[3]  << 24) >>> 0) % modulo\n    let y = ((hashBytes[4] | hashBytes[5] << 8 | hashBytes[6]  << 16 | hashBytes[7]  << 24) >>> 0) % modulo\n    let z = ((hashBytes[8] | hashBytes[9] << 8 | hashBytes[10] << 16 | hashBytes[11] << 24) >>> 0) % modulo\n    const probes = [x]\n    for (let i = 1; i < this.numProbes; i++) {\n      x = (x + y) % modulo\n      y = (y + z) % modulo\n      probes.push(x)\n    }\n    return probes\n  }\n\n  /**\n   * Sets the Bloom filter bits corresponding to a given SHA-256 hash (given as hex string).\n   */\n  addHash(hash) {\n    for (let probe of this.getProbes(hash)) {\n      this.bits[probe >>> 3] |= 1 << (probe & 7)\n    }\n  }\n\n  /**\n   * Tests whether a given SHA-256 hash (given as hex string) is contained in the Bloom filter.\n   */\n  containsHash(hash) {\n    if (this.numEntries === 0) return false\n    for (let probe of this.getProbes(hash)) {\n      if ((this.bits[probe >>> 3] & (1 << (probe & 7))) === 0) {\n        return false\n      }\n    }\n    return true\n  }\n}\n\n/**\n * Encodes a sorted array of SHA-256 hashes (as hexadecimal strings) into a byte array.\n */\nfunction encodeHashes(encoder, hashes) {\n  if (!Array.isArray(hashes)) throw new TypeError('hashes must be an array')\n  encoder.appendUint32(hashes.length)\n  for (let i = 0; i < hashes.length; i++) {\n    if (i > 0 && hashes[i - 1] >= hashes[i]) throw new RangeError('hashes must be sorted')\n    const bytes = hexStringToBytes(hashes[i])\n    if (bytes.byteLength !== HASH_SIZE) throw new TypeError('heads hashes must be 256 bits')\n    encoder.appendRawBytes(bytes)\n  }\n}\n\n/**\n * Decodes a byte array in the format returned by encodeHashes(), and returns its content as an\n * array of hex strings.\n */\nfunction decodeHashes(decoder) {\n  let length = decoder.readUint32(), hashes = []\n  for (let i = 0; i < length; i++) {\n    hashes.push(bytesToHexString(decoder.readRawBytes(HASH_SIZE)))\n  }\n  return hashes\n}\n\n/**\n * Takes a sync message of the form `{heads, need, have, changes}` and encodes it as a byte array for\n * transmission.\n */\nfunction encodeSyncMessage(message) {\n  const encoder = new Encoder()\n  encoder.appendByte(MESSAGE_TYPE_SYNC)\n  encodeHashes(encoder, message.heads)\n  encodeHashes(encoder, message.need)\n  encoder.appendUint32(message.have.length)\n  for (let have of message.have) {\n    encodeHashes(encoder, have.lastSync)\n    encoder.appendPrefixedBytes(have.bloom)\n  }\n  encoder.appendUint32(message.changes.length)\n  for (let change of message.changes) {\n    encoder.appendPrefixedBytes(change)\n  }\n  return encoder.buffer\n}\n\n/**\n * Takes a binary-encoded sync message and decodes it into the form `{heads, need, have, changes}`.\n */\nfunction decodeSyncMessage(bytes) {\n  const decoder = new Decoder(bytes)\n  const messageType = decoder.readByte()\n  if (messageType !== MESSAGE_TYPE_SYNC) {\n    throw new RangeError(`Unexpected message type: ${messageType}`)\n  }\n  const heads = decodeHashes(decoder)\n  const need = decodeHashes(decoder)\n  const haveCount = decoder.readUint32()\n  let message = {heads, need, have: [], changes: []}\n  for (let i = 0; i < haveCount; i++) {\n    const lastSync = decodeHashes(decoder)\n    const bloom = decoder.readPrefixedBytes(decoder)\n    message.have.push({lastSync, bloom})\n  }\n  const changeCount = decoder.readUint32()\n  for (let i = 0; i < changeCount; i++) {\n    const change = decoder.readPrefixedBytes()\n    message.changes.push(change)\n  }\n  // Ignore any trailing bytes -- they can be used for extensions by future versions of the protocol\n  return message\n}\n\n/**\n * Takes a SyncState and encodes as a byte array those parts of the state that should persist across\n * an application restart or disconnect and reconnect. The ephemeral parts of the state that should\n * be cleared on reconnect are not encoded.\n */\nfunction encodeSyncState(syncState) {\n  const encoder = new Encoder()\n  encoder.appendByte(PEER_STATE_TYPE)\n  encodeHashes(encoder, syncState.sharedHeads)\n  return encoder.buffer\n}\n\n/**\n * Takes a persisted peer state as encoded by `encodeSyncState` and decodes it into a SyncState\n * object. The parts of the peer state that were not encoded are initialised with default values.\n */\nfunction decodeSyncState(bytes) {\n  const decoder = new Decoder(bytes)\n  const recordType = decoder.readByte()\n  if (recordType !== PEER_STATE_TYPE) {\n    throw new RangeError(`Unexpected record type: ${recordType}`)\n  }\n  const sharedHeads = decodeHashes(decoder)\n  return Object.assign(initSyncState(), { sharedHeads })\n}\n\n/**\n * Constructs a Bloom filter containing all changes that are not one of the hashes in\n * `lastSync` or its transitive dependencies. In other words, the filter contains those\n * changes that have been applied since the version identified by `lastSync`. Returns\n * an object of the form `{lastSync, bloom}` as required for the `have` field of a sync\n * message.\n */\nfunction makeBloomFilter(backend, lastSync) {\n  const newChanges = Backend.getChanges(backend, lastSync)\n  const hashes = newChanges.map(change => decodeChangeMeta(change, true).hash)\n  return {lastSync, bloom: new BloomFilter(hashes).bytes}\n}\n\n/**\n * Call this function when a sync message is received from another node. The `message` argument\n * needs to already have been decoded using `decodeSyncMessage()`. This function determines the\n * changes that we need to send to the other node in response. Returns an array of changes (as\n * byte arrays).\n */\nfunction getChangesToSend(backend, have, need) {\n  if (have.length === 0) {\n    return need.map(hash => Backend.getChangeByHash(backend, hash)).filter(change => change !== undefined)\n  }\n\n  let lastSyncHashes = {}, bloomFilters = []\n  for (let h of have) {\n    for (let hash of h.lastSync) lastSyncHashes[hash] = true\n    bloomFilters.push(new BloomFilter(h.bloom))\n  }\n\n  // Get all changes that were added since the last sync\n  const changes = Backend.getChanges(backend, Object.keys(lastSyncHashes))\n    .map(change => decodeChangeMeta(change, true))\n\n  let changeHashes = {}, dependents = {}, hashesToSend = {}\n  for (let change of changes) {\n    changeHashes[change.hash] = true\n\n    // For each change, make a list of changes that depend on it\n    for (let dep of change.deps) {\n      if (!dependents[dep]) dependents[dep] = []\n      dependents[dep].push(change.hash)\n    }\n\n    // Exclude any change hashes contained in one or more Bloom filters\n    if (bloomFilters.every(bloom => !bloom.containsHash(change.hash))) {\n      hashesToSend[change.hash] = true\n    }\n  }\n\n  // Include any changes that depend on a Bloom-negative change\n  let stack = Object.keys(hashesToSend)\n  while (stack.length > 0) {\n    const hash = stack.pop()\n    if (dependents[hash]) {\n      for (let dep of dependents[hash]) {\n        if (!hashesToSend[dep]) {\n          hashesToSend[dep] = true\n          stack.push(dep)\n        }\n      }\n    }\n  }\n\n  // Include any explicitly requested changes\n  let changesToSend = []\n  for (let hash of need) {\n    hashesToSend[hash] = true\n    if (!changeHashes[hash]) { // Change is not among those returned by getMissingChanges()?\n      const change = Backend.getChangeByHash(backend, hash)\n      if (change) changesToSend.push(change)\n    }\n  }\n\n  // Return changes in the order they were returned by getMissingChanges()\n  for (let change of changes) {\n    if (hashesToSend[change.hash]) changesToSend.push(change.change)\n  }\n  return changesToSend\n}\n\nfunction initSyncState() {\n  return {\n    sharedHeads: [],\n    lastSentHeads: [],\n    theirHeads: null,\n    theirNeed: null,\n    theirHave: null,\n    sentHashes: {},\n  }\n}\n\nfunction compareArrays(a, b) {\n    return (a.length === b.length) && a.every((v, i) => v === b[i])\n}\n\n/**\n * Given a backend and what we believe to be the state of our peer, generate a message which tells\n * them about we have and includes any changes we believe they need\n */\nfunction generateSyncMessage(backend, syncState) {\n  if (!backend) {\n    throw new Error(\"generateSyncMessage called with no Automerge document\")\n  }\n  if (!syncState) {\n    throw new Error(\"generateSyncMessage requires a syncState, which can be created with initSyncState()\")\n  }\n\n  let { sharedHeads, lastSentHeads, theirHeads, theirNeed, theirHave, sentHashes } = syncState\n  const ourHeads = Backend.getHeads(backend)\n\n  // Hashes to explicitly request from the remote peer: any missing dependencies of unapplied\n  // changes, and any of the remote peer's heads that we don't know about\n  const ourNeed = Backend.getMissingDeps(backend, theirHeads || [])\n\n  // There are two reasons why ourNeed may be nonempty: 1. we might be missing dependencies due to\n  // Bloom filter false positives; 2. we might be missing heads that the other peer mentioned\n  // because they (intentionally) only sent us a subset of changes. In case 1, we leave the `have`\n  // field of the message empty because we just want to fill in the missing dependencies for now.\n  // In case 2, or if ourNeed is empty, we send a Bloom filter to request any unsent changes.\n  let ourHave = []\n  if (!theirHeads || ourNeed.every(hash => theirHeads.includes(hash))) {\n    ourHave = [makeBloomFilter(backend, sharedHeads)]\n  }\n\n  // Fall back to a full re-sync if the sender's last sync state includes hashes\n  // that we don't know. This could happen if we crashed after the last sync and\n  // failed to persist changes that the other node already sent us.\n  if (theirHave && theirHave.length > 0) {\n    const lastSync = theirHave[0].lastSync\n    if (!lastSync.every(hash => Backend.getChangeByHash(backend, hash))) {\n      // we need to queue them to send us a fresh sync message, the one they sent is uninteligible so we don't know what they need\n      const resetMsg = {heads: ourHeads, need: [], have: [{ lastSync: [], bloom: new Uint8Array(0) }], changes: []}\n      return [syncState, encodeSyncMessage(resetMsg)]\n    }\n  }\n\n  // XXX: we should limit ourselves to only sending a subset of all the messages, probably limited by a total message size\n  //      these changes should ideally be RLE encoded but we haven't implemented that yet.\n  let changesToSend = Array.isArray(theirHave) && Array.isArray(theirNeed) ? getChangesToSend(backend, theirHave, theirNeed) : []\n\n  // If the heads are equal, we're in sync and don't need to do anything further\n  const headsUnchanged = Array.isArray(lastSentHeads) && compareArrays(ourHeads, lastSentHeads)\n  const headsEqual = Array.isArray(theirHeads) && compareArrays(ourHeads, theirHeads)\n  if (headsUnchanged && headsEqual && changesToSend.length === 0) {\n    // no need to send a sync message if we know we're synced!\n    return [syncState, null]\n  }\n\n  // TODO: this recomputes the SHA-256 hash of each change; we should restructure this to avoid the\n  // unnecessary recomputation\n  changesToSend = changesToSend.filter(change => !sentHashes[decodeChangeMeta(change, true).hash])\n\n  // Regular response to a sync message: send any changes that the other node\n  // doesn't have. We leave the \"have\" field empty because the previous message\n  // generated by `syncStart` already indicated what changes we have.\n  const syncMessage = {heads: ourHeads, have: ourHave, need: ourNeed, changes: changesToSend}\n  if (changesToSend.length > 0) {\n    sentHashes = copyObject(sentHashes)\n    for (const change of changesToSend) {\n      sentHashes[decodeChangeMeta(change, true).hash] = true\n    }\n  }\n\n  syncState = Object.assign({}, syncState, {lastSentHeads: ourHeads, sentHashes})\n  return [syncState, encodeSyncMessage(syncMessage)]\n}\n\n/**\n * Computes the heads that we share with a peer after we have just received some changes from that\n * peer and applied them. This may not be sufficient to bring our heads in sync with the other\n * peer's heads, since they may have only sent us a subset of their outstanding changes.\n *\n * `myOldHeads` are the local heads before the most recent changes were applied, `myNewHeads` are\n * the local heads after those changes were applied, and `ourOldSharedHeads` is the previous set of\n * shared heads. Applying the changes will have replaced some heads with others, but some heads may\n * have remained unchanged (because they are for branches on which no changes have been added). Any\n * such unchanged heads remain in the sharedHeads. Any sharedHeads that were replaced by applying\n * changes are also replaced as sharedHeads. This is safe because if we received some changes from\n * another peer, that means that peer had those changes, and therefore we now both know about them.\n */\nfunction advanceHeads(myOldHeads, myNewHeads, ourOldSharedHeads) {\n  const newHeads = myNewHeads.filter((head) => !myOldHeads.includes(head))\n  const commonHeads = ourOldSharedHeads.filter((head) => myNewHeads.includes(head))\n  const advancedHeads = [...new Set([...newHeads, ...commonHeads])].sort()\n  return advancedHeads\n}\n\n\n/**\n * Given a backend, a message message and the state of our peer, apply any changes, update what\n * we believe about the peer, and (if there were applied changes) produce a patch for the frontend\n */\nfunction receiveSyncMessage(backend, oldSyncState, binaryMessage) {\n  if (!backend) {\n    throw new Error(\"generateSyncMessage called with no Automerge document\")\n  }\n  if (!oldSyncState) {\n    throw new Error(\"generateSyncMessage requires a syncState, which can be created with initSyncState()\")\n  }\n\n  let { sharedHeads, lastSentHeads, sentHashes } = oldSyncState, patch = null\n  const message = decodeSyncMessage(binaryMessage)\n  const beforeHeads = Backend.getHeads(backend)\n\n  // If we received changes, we try to apply them to the document. There may still be missing\n  // dependencies due to Bloom filter false positives, in which case the backend will enqueue the\n  // changes without applying them. The set of changes may also be incomplete if the sender decided\n  // to break a large set of changes into chunks.\n  if (message.changes.length > 0) {\n    [backend, patch] = Backend.applyChanges(backend, message.changes)\n    sharedHeads = advanceHeads(beforeHeads, Backend.getHeads(backend), sharedHeads)\n  }\n\n  // If heads are equal, indicate we don't need to send a response message\n  if (message.changes.length === 0 && compareArrays(message.heads, beforeHeads)) {\n    lastSentHeads = message.heads\n  }\n\n  // If all of the remote heads are known to us, that means either our heads are equal, or we are\n  // ahead of the remote peer. In this case, take the remote heads to be our shared heads.\n  const knownHeads = message.heads.filter(head => Backend.getChangeByHash(backend, head))\n  if (knownHeads.length === message.heads.length) {\n    sharedHeads = message.heads\n    // If the remote peer has lost all its data, reset our state to perform a full resync\n    if (message.heads.length === 0) {\n      lastSentHeads = []\n      sentHashes = []\n    }\n  } else {\n    // If some remote heads are unknown to us, we add all the remote heads we know to\n    // sharedHeads, but don't remove anything from sharedHeads. This might cause sharedHeads to\n    // contain some redundant hashes (where one hash is actually a transitive dependency of\n    // another), but this will be cleared up as soon as we know all the remote heads.\n    sharedHeads = [...new Set(knownHeads.concat(sharedHeads))].sort()\n  }\n\n  const syncState = {\n    sharedHeads, // what we have in common to generate an efficient bloom filter\n    lastSentHeads,\n    theirHave: message.have, // the information we need to calculate the changes they need\n    theirHeads: message.heads,\n    theirNeed: message.need,\n    sentHashes\n  }\n  return [backend, syncState, patch]\n}\n\nmodule.exports = {\n  receiveSyncMessage, generateSyncMessage,\n  encodeSyncMessage, decodeSyncMessage,\n  initSyncState, encodeSyncState, decodeSyncState,\n  BloomFilter // BloomFilter is a private API, exported only for testing purposes\n}\n"]},"metadata":{},"sourceType":"script"}